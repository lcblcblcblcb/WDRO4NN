from __future__ import annotations
import torch
from torch import Tensor

# ---------------------------------------------------------------------
# Global bound â€“ to be implemented
# ---------------------------------------------------------------------
def global_L(model, **kwargs) -> Tensor:   # noqa: N802
    """
    Placeholder for

        L_global = max_{D} âˆš2 Â· â€–Wâ‚‚ D Wâ‚â€–â‚‚

    or the analogue youâ€™ll derive for deeper nets.

    Parameters
    ----------
    model : nn.Module
        The network whose Lipschitz constant you want.
    **kwargs
        Optional future arguments (device, max_masks, rng, â€¦).

    Returns
    -------
    0-D tensor
        Raises `NotImplementedError` for now.
    """
    raise NotImplementedError(
        "global_L is not yet implemented â€“ decide on the formula first."
    )


# ---------------------------------------------------------------------
# Per-sample (local) bound â€“ to be implemented
# ---------------------------------------------------------------------
def local_L(model, x: Tensor, **kwargs) -> Tensor:   # noqa: N802
    """
    Placeholder for a *sample-dependent* Lipschitz constant, e.g.

        L_i = âˆš2 Â· max_{D âˆˆ ğ’Ÿ(x)} â€–Wâ‚‚ D Wâ‚â€–â‚‚
              where ğ’Ÿ(x) are masks reachable from x.

    Parameters
    ----------
    model : nn.Module
    x     : Tensor
        One input sample.
    **kwargs
        Extra knobs you may add later (include_anchor, device, â€¦).

    Returns
    -------
    0-D tensor
        Raises `NotImplementedError` for now.
    """
    raise NotImplementedError(
        "local_L is not yet implemented â€“ decide on the formula first."
    )